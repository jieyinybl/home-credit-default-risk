{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import common packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import specific packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import lightgbm as gbm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load data\n",
    "\n",
    "First we load all the files saved in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_test.csv\nHomeCredit_columns_description.csv\nPOS_CASH_balance.csv\ncredit_card_balance.csv\ninstallments_payments.csv\napplication_train.csv\nbureau.csv\nprevious_application.csv\nbureau_balance.csv\nsample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "data_path = './data'\n",
    "\n",
    "for filename in os.listdir(data_path):\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(data_path, 'application_test.csv'))\n",
    "col_desc = pd.read_csv(os.path.join(data_path, 'HomeCredit_columns_description.csv'))\n",
    "pos_cash_balance = pd.read_csv(os.path.join(data_path, 'POS_CASH_balance.csv'))\n",
    "credit_card_balance = pd.read_csv(os.path.join(data_path, 'credit_card_balance.csv'))\n",
    "installments_payments = pd.read_csv(os.path.join(data_path, 'installments_payments.csv'))\n",
    "train = pd.read_csv(os.path.join(data_path, 'application_train.csv'))\n",
    "bureau = pd.read_csv(os.path.join(data_path, 'bureau.csv'))\n",
    "prev_application = pd.read_csv(os.path.join(data_path, 'previous_application.csv'))\n",
    "bureau_balance = pd.read_csv(os.path.join(data_path, 'bureau_balance.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "This notebook will do the following:\n",
    "\n",
    "- Label encoding categorical features with `sklearn.preprocessing.LabelEncoder`\n",
    "- Handel missing features:\n",
    "\t- There are several strategies to handle the missing features: here we will set the values to some values.\n",
    "\t- We use the `df[num_var].fillna(-999)` here. But there are more options if you use the `sklearn.preprocessing.Imputer`\n",
    "\n",
    "\n",
    "```from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(strategy='median')\n",
    "num_vars = df.select_dtypes['float64', 'float32', 'int64', 'int32'].columns.tolist()\n",
    "df[num_vars] = imputer.fit_transform(df[num_vars])\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelEncoder()\n",
    "\n",
    "def label_encoding_cat(df):\n",
    "    df = df.copy()\n",
    "    cat_var = df.select_dtypes('object').columns.tolist()\n",
    "    for col in cat_var:\n",
    "        df[col] = lb.fit_transform(df[col].astype('str'))\n",
    "    return df\n",
    "\n",
    "def fill_na(df):\n",
    "    df = df.copy()\n",
    "    num_var = df.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist()\n",
    "    df[num_var] = df[num_var].fillna(-999)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregated features\n",
    "\n",
    "Let's aggregate the numerical features for each *SK_ID_CURR*.\n",
    "\n",
    "```\n",
    "df.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "```\n",
    "\n",
    "If only certain columns needs to be aggregated:\n",
    "\n",
    "```\n",
    "df.groupby(['col1', ..., 'coln'], as_index=False).mean()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = ['%s_%s'%(s, l) for s in bureau.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist() if s!='SK_ID_CURR' for l in ['mean', 'count', 'median', 'max']]\n",
    "agg_bureau = bureau.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "agg_bureau.columns = ['SK_ID_CURR'] + label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_2 = ['%s_%s'%(s, l) for s in prev_application.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist() if s not in ['SK_ID_CURR'] for l in ['mean', 'count', 'median', 'max']]\n",
    "agg_prev_application = prev_application.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "agg_prev_application.columns = ['SK_ID_CURR'] + label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join bureau and bureau_balance to get SK_ID_CURR to bureau_balance\n",
    "bureau_balance = pd.read_csv(os.path.join(data_path, 'bureau_balance.csv'))\n",
    "bureau_balance = pd.merge(bureau_balance, bureau[['SK_ID_CURR', 'SK_ID_BUREAU']], how='left', on='SK_ID_BUREAU')\n",
    "\n",
    "label_3 = ['%s_%s'%(s, l) for s in bureau_balance.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist() if s not in ['SK_ID_BUREAU'] for l in ['mean', 'count', 'median', 'max']]\n",
    "agg_bureau_balance = bureau_balance.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "agg_bureau_balance.columns = ['SK_ID_CURR'] + label_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_4 = ['%s_%s'%(s, l) for s in credit_card_balance.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist() if s not in ['SK_ID_CURR'] for l in ['mean', 'count', 'median', 'max']]\n",
    "agg_credit_card_balance = credit_card_balance.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "agg_credit_card_balance.columns = ['SK_ID_CURR'] + label_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_5 = ['%s_%s'%(s, l) for s in installments_payments.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist() if s not in ['SK_ID_CURR'] for l in ['mean', 'count', 'median', 'max']]\n",
    "agg_installments_payments = installments_payments.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "agg_installments_payments.columns = ['SK_ID_CURR'] + label_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_6 = ['%s_%s'%(s, l) for s in pos_cash_balance.select_dtypes(['float64', 'float32', 'int64', 'int32']).columns.tolist() if s not in ['SK_ID_CURR'] for l in ['mean', 'count', 'median', 'max']]\n",
    "agg_pos_cash_balance = pos_cash_balance.groupby('SK_ID_CURR').agg(['mean', 'count', 'median', 'max']).reset_index()\n",
    "agg_pos_cash_balance.columns = ['SK_ID_CURR'] + label_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(label_1,label_2,label_3,label_4,label_5,label_6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we combine the training set and testing set together, so that we can apply `label_encoding_cat` und `fill_na` afterwards.\n",
    "We merge the aggregated table to the train & test table on `SK_ID_CURR`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_te = train.drop('TARGET', axis=1).append(test)\\\n",
    "    .pipe(label_encoding_cat)\\\n",
    "    .pipe(fill_na)\\\n",
    "    .merge(agg_bureau, how='left', on='SK_ID_CURR')\\\n",
    "    .merge(agg_credit_card_balance, how='left', on='SK_ID_CURR')\\\n",
    "    .merge(agg_pos_cash_balance, how='left', on='SK_ID_CURR')\\\n",
    "    .merge(agg_prev_application, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri = train.shape[0]\n",
    "y = train.TARGET.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and testing df.\n",
    "tr_te.drop('SK_ID_CURR', axis=1, inplace=True)\n",
    "tr = fill_na(tr_te).iloc[:tri, :].copy()\n",
    "te = fill_na(tr_te).iloc[tri:, :].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model: Light Gradient Boosting Machine\n",
    "\n",
    "I added up [LightGBM](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html) as that I noticed on Kaggle this would achieve higher AUC_ROC score (about 0.78) compared to RandomForestClassifier (auc_roc at about 0.71). \n",
    "\n",
    "Before going on to training, let's explain the steps of training with LightGBM.\n",
    "\n",
    "**Load data**\n",
    "\n",
    "```\n",
    "train_data = gmb.Dataset(df)\n",
    "# OR \n",
    "train_data = gmb.Dataset(data, label=label)\n",
    "```\n",
    "\n",
    "**Booster parameters**\n",
    "\n",
    "```\n",
    "param = {'num_leaves':31, 'num_trees':100, 'objective':'binary'}\n",
    "\n",
    "```\n",
    "\n",
    "**Metric parameters**\n",
    "\n",
    "Here we can set it to `auc`.\n",
    "```\n",
    "param['metric'] = 'auc'\n",
    "```\n",
    "\n",
    "**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dparam = {'objective' : 'binary',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'metric' : 'auc',\n",
    "          'nthread' : 4,\n",
    "          'shrinkage_rate':0.025,\n",
    "          'max_depth':8,\n",
    "          'min_data_in_leaf':100,\n",
    "          'min_child_weight': 2,\n",
    "          'bagging_fraction':0.75,\n",
    "          'feature_fraction':0.75,\n",
    "          'min_split_gain':.01,\n",
    "          'lambda_l1':1,\n",
    "          'lambda_l2':1,\n",
    "          'num_leaves':36} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_preds = np.zeros(train.shape[0])\n",
    "sub_preds = np.zeros(test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.872276\tval's auc: 0.782073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.925911\tval's auc: 0.781464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.957165\tval's auc: 0.780306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 AUC: 0.780306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.874167\tval's auc: 0.783202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.926376\tval's auc: 0.782785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.956695\tval's auc: 0.780828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  2 AUC: 0.780828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.872797\tval's auc: 0.782933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.924618\tval's auc: 0.782177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.955913\tval's auc: 0.780925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  3 AUC: 0.780925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.87251\tval's auc: 0.780649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.925375\tval's auc: 0.78074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.956294\tval's auc: 0.779591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  4 AUC: 0.779591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.873406\tval's auc: 0.779406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.925119\tval's auc: 0.778319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.956101\tval's auc: 0.777131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  5 AUC: 0.777131\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "feats = [f for f in train.columns if f not in ['SK_ID_CURR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.872276\tval's auc: 0.782073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.925911\tval's auc: 0.781464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.957165\tval's auc: 0.780306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 AUC: 0.780306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.874167\tval's auc: 0.783202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.926376\tval's auc: 0.782785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.956695\tval's auc: 0.780828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  2 AUC: 0.780828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.872797\tval's auc: 0.782933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.924618\tval's auc: 0.782177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.955913\tval's auc: 0.780925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  3 AUC: 0.780925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.87251\tval's auc: 0.780649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.925375\tval's auc: 0.78074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.956294\tval's auc: 0.779591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  4 AUC: 0.779591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's auc: 0.873406\tval's auc: 0.779406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\ttrain's auc: 0.925119\tval's auc: 0.778319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttrain's auc: 0.956101\tval's auc: 0.777131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  5 AUC: 0.777131\n"
     ]
    }
   ],
   "source": [
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(tr)):\n",
    "    dtrain = gbm.Dataset(tr.iloc[trn_idx], y.iloc[trn_idx])\n",
    "    dval = gbm.Dataset(tr.iloc[val_idx], y.iloc[val_idx])\n",
    "    m_gbm = gbm.train(params=Dparam, train_set=dtrain, num_boost_round=3000, verbose_eval=1000, valid_sets=[dtrain, dval],valid_names=['train','val'])\n",
    "    off_preds[val_idx] = m_gbm.predict(tr.iloc[val_idx])\n",
    "    sub_preds += m_gbm.predict(te) / folds.n_splits\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df['feature'] = feats\n",
    "    fold_importance_df['fold'] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    print('Fold %2d AUC: %.6f' % (n_fold+1, roc_auc_score(y.iloc[val_idx], off_preds[val_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auc on training set is higher than it on validation set, so we can see that the model is overfitting the training data. There is still room to improve its performance on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train model: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Fold: train AUC 1.000000, val AUC 0.711845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Fold: train AUC 1.000000, val AUC 0.713323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Fold: train AUC 1.000000, val AUC 0.713551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Fold: train AUC 1.000000, val AUC 0.712408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Fold: train AUC 1.000000, val AUC 0.715944\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "for n_fold, (trn_idx, val_idx) in enumerate(folds.split(tr)):\n",
    "    clone_clf = clone(rf_clf)\n",
    "    clone_clf.fit(tr.iloc[trn_idx], y.iloc[trn_idx])\n",
    "    train_proba = clone_clf.predict_proba(tr.iloc[trn_idx])\n",
    "    val_proba = clone_clf.predict_proba(tr.iloc[val_idx])\n",
    "    trn_roc_auc = roc_auc_score(y.iloc[trn_idx], train_proba[:,1])\n",
    "    val_roc_auc = roc_auc_score(y.iloc[val_idx], val_proba[:,1])\n",
    "    print('%d Fold: train AUC %.6f, val AUC %.6f' % (n_fold+1, trn_roc_auc, val_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The auc on training set is higher than it on validation set, so we can see that the model is overfitting the training data. There is still room to improve its performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
